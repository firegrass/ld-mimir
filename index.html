<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>Mímir: Semantic Content Pipeline</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" type="text/css" href="style.css">
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
</head>
<body>
<header>

<h1 class="title">Mímir: Semantic Content Pipeline</h1>



</header>
<nav id="TOC">
<ul>
<li><a href="#so-what-is-it">So what is it?</a></li>
<li><a href="#so-what-is-it-1">So what is it?</a></li>
<li><a href="#so-what-is-it-2">So what is it?</a><ul>
<li><a href="#a-web-based-integrated-development-environment">A web based Integrated Development Environment</a></li>
<li><a href="#a-version-control-system">A version control system</a></li>
<li><a href="#a-compiler">A compiler</a></li>
<li><a href="#a-collaboration-and-project-management-site">A collaboration and project management site</a></li>
<li><a href="#a-continuous-integration-process">A continuous integration process</a></li>
<li><a href="#orchestration-to-manage-development-and-ci-environments-without-admin-overhead">Orchestration to manage development and CI environments without admin overhead</a></li>
</ul></li>
<li><a href="#what-you-should-probably-read-before-working-on-this-project">What you should probably read before working on this project</a></li>
<li><a href="#running-a-mimir-instance">Running a Mimir Instance</a></li>
<li><a href="#running-the-old-linked-data-demo-standalone">Running the old Linked Data Demo Standalone</a></li>
<li><a href="#architecture">Architecture</a><ul>
<li><a href="#engineering-versus-office-model-of-document-production">Engineering versus office model of document production</a></li>
<li><a href="#plain-text">Plain-text</a></li>
<li><a href="#what-is-provenance">What is Provenance?</a></li>
<li><a href="#provenance-extraction-from-version-control">Provenance extraction from version control</a></li>
<li><a href="#desired-behaviour">Desired behaviour</a></li>
<li><a href="#translation">Translation</a></li>
<li><a href="#uri-generation">URI generation</a><ul>
<li><a href="#on-short-hash-length">On short hash length</a></li>
<li><a href="#dereferencability">Dereferencability</a></li>
<li><a href="#resource-uri-generation">Resource URI generation</a></li>
</ul></li>
</ul></li>
</ul>
</nav>

<section class="main">
<h2 id="so-what-is-it">So what is it?</h2>
<p>We are building a set of tools that can be used together to create and maintain a semantic knowledge base and derived works.</p>
<h2 id="so-what-is-it-1">So what is it?</h2>
<p>Plain-text files and a modern version control system can be used to create a content repository and publishing pipeline. Version control history can be translated into standard compliant W3C provenance graphs. Semantics can be embedded in plain-text content directly, inferred from structure, extracted using natural language processing or stored as annotations. Print quality documents and web content can be produced from semantic data as the version control system is updated.</p>
<h2 id="so-what-is-it-2">So what is it?</h2>
<p>We are going to try to use similar tools and processes to those we use as developers to produce software to enable NICE to produce semantic content.</p>
<h3 id="a-web-based-integrated-development-environment">A web based Integrated Development Environment</h3>
<figure>
<img src="editor.png" alt="Editor" /><figcaption>Editor</figcaption>
</figure>
<h3 id="a-version-control-system">A version control system</h3>
<p>Git.</p>
<h3 id="a-compiler">A compiler</h3>
<p>Translates plain-text files into an OWL2 knowledge base. This can be syndicated directly and translated into web / pdf / ebook / etc content.</p>
<h3 id="a-collaboration-and-project-management-site">A collaboration and project management site</h3>
<p><a href="http://gitlab.com">Gitlab</a> A github clone we can run behind the firewall.</p>
<h3 id="a-continuous-integration-process">A continuous integration process</h3>
<p>Probably based around <a href="http://drone.io">drone</a></p>
<h3 id="orchestration-to-manage-development-and-ci-environments-without-admin-overhead">Orchestration to manage development and CI environments without admin overhead</h3>
<p>Environments will be executed in <a href="http://docker.io">docker</a>. This makes creation and update of large numbers of instances of the editor and tool chain possible. It also means we need to deploy to Linux, not windows.</p>
<h2 id="what-you-should-probably-read-before-working-on-this-project">What you should probably read before working on this project</h2>
<p>Many of the technologies used are likely to be unfamiliar to people with a background in ASP/.NET. Semantic web technology hasn’t seen much use in the .NET world at all; mostly it’s from Java land and used by specialists.</p>
<h2 id="running-a-mimir-instance">Running a Mimir Instance</h2>
<p>To use Mimir you need to run and link the old linked data demo - this is used as a source of linked data.</p>
<p>To begin, pull the olddemo image.</p>
<pre class="sh"><code>$ docker pull nice/olddemo</code></pre>
<p>Now we need to run it and give it a name. This name is important, so please use ‘olddemo’</p>
<pre class="sh"><code>$ docker run --name olddemo nice/olddemo</code></pre>
<p>Next we pull the Mimir image</p>
<pre class="sh"><code>$ docker pull nice/mimir</code></pre>
<p>Now we need to run mimir. To do this we need to map a directory, forward a port and link to the ‘olddata’ image.</p>
<pre class="sh"><code>$ docker run --link olddemo:olddemo -v ~/my-project-files:/tmp -p 3424:80 --name mimir nice/mimir</code></pre>
<p>This command:</p>
<ul>
<li>forwards port 80 of the docker container to port 3424.</li>
<li>maps the local folder ~/my-project-files to /tmp in the container. This is the folder mimir will use.</li>
<li>creates a link to olddemo. This generates a bunch of environment variables used by mimir.</li>
</ul>
<p>To connect to the Mimir instance, you need the docker host ip address. On Mac OS X, this is:</p>
<pre class="sh"><code>$boot2docker ip</code></pre>
<p>You can then navigate to (in this example’s case) http://${DOCKER_HOST}:3424 and you’re done.</p>
<h2 id="running-the-old-linked-data-demo-standalone">Running the old Linked Data Demo Standalone</h2>
<p>Assuming you have a docker host (boot2docker for example), the process for installing the container:</p>
<pre class="sh"><code>$ docker pull nice/olddemo</code></pre>
<p>And then running:</p>
<pre class="sh"><code>$ docker run nice/olddemo</code></pre>
<p>To find the IP address (the ${DOCKER_HOST}) run:</p>
<pre class="sh"><code>$ boot2docker ip</code></pre>
<p>Then you can navigate to http://${DOCKER_HOST}/index.html</p>
<p>That’s it!</p>
<h1 id="architecture">Architecture</h1>
<h2 id="engineering-versus-office-model-of-document-production">Engineering versus office model of document production</h2>
<p>It is possible to separate approaches to collaboratively constructing documents into two camps<span class="citation" data-cites="Plaintext_Please"><sup>1</sup></span> - the office model and the engineering model. The office model is familiar to most people; a set of tools centered around a word processor and a number of large files are the center of their work. Changes to this work are tracked inside these large files and in various ad-hoc ways. Concurrent editing is difficult unless authors are in the same room and merging changes between different groups working concurrently is usually a manual process. The final output is usually the word processor file without change tracking data, possibly transliterated to formats more suitable for print or web.</p>
<p>In the engineering model, a larger number of plaintext files and a version control system become the center of the project along with a larger suite of more specific tools than a word processor. Changes to these files are tracked externally, in the version control system. Plain text formats are used because of the relative ease of determining the differences between two versions of the same text. Transformation of plain-text is usually performed by different tools than those used for editing it.</p>
<h2 id="plain-text">Plain-text</h2>
<p>Files that contain markup or other data are generally considered plain-text, as long as the entirety remains in directly human-readable form. Markup formats such as HTML and markdown are also plain-text as Coombs, Renear, and DeRose argue<span class="citation" data-cites="Coombs:1987:MSF:32206.32209"><sup>2</sup></span>, punctuation is itself markup. A binary file (such as a JPEG image or a Word Document) is a sequence of bytes which requires interpretation before it can be understood by humans. Some rich text formats such as Microsoft Word’s .xdoc are superficially plain-text but are probably better classed as text encoded binary formats as very few humans would be able to make sense of such a document without the application that renders it.</p>
<p>A consideration when choosing between plain-text formats is the ease of resolving conflicts when multiple agents are collaborating on changes to a single file. Line and character oriented differencing algorithms are efficient and well understood. Differencing rich text formats that have structures that span multiple lines such as HTML or XML is more complex. Using textual differencing on these can produce invalid results and relies on users having knowledge of the format to resolve problems. These same constrains apply to the operational transformation algorithms<span class="citation" data-cites="Sun98operationaltransformation"><sup>3</sup></span> that collaborative real-time editors use.</p>
<h2 id="what-is-provenance">What is Provenance?</h2>
<blockquote>
<p>Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness<span class="citation" data-cites="McGuinness:13:PTP"><sup>4</sup></span>.</p>
</blockquote>
<p>Provenance is particularly important to the semantic web community as they need to track the complicated web of trust between linked data sources. To meet these needs, the W3C published the PROV standard.</p>
<p>The PROV data model supports the following:</p>
<ul>
<li>The core concepts of identifying an object, attributing the object to person or entity, and representing processing steps</li>
<li>Accessing provenance-related information expressed in other standards</li>
<li>Accessing provenance</li>
<li>The provenance of provenance</li>
<li>Reproducibility</li>
<li>Versioning</li>
<li>Representing procedures</li>
<li>Representing derivation</li>
</ul>
<h2 id="provenance-extraction-from-version-control">Provenance extraction from version control</h2>
<p>The Git2Prov project<span class="citation" data-cites="denies_iswc_2013"><sup>5</sup></span> demonstrates a model for extracting PROV from a git repository. A altered version of this model is presented here that demonstrates the core concepts.</p>
<p>A git repository can be viewed as a sequence of linked commits. Each commit contains the complete repository state at that point and has a unique hash code along with metadata describing the change and identifying the users involved. A diff can be created for any pair of commits that will show altered, added, renamed and copied files.</p>
<p>Our process to translate git into W3C PROV differs slightly from this work (which has a node implementation) and is described here.</p>
<h2 id="desired-behaviour">Desired behaviour</h2>
<p>The generated provenance should be a idempotent injective transformation of the git object database. Generation of provenance from a database should always produce the same provenance, no matter how many times it is executed. This is critical as the linked data project is a distributed system, with many clones of the content repository.</p>
<h2 id="translation">Translation</h2>
<figure>
<img src="git.png" alt="Git object structure (c=commit d=diff f=changed files)" /><figcaption>Git object structure (c=commit d=diff f=changed files)</figcaption>
</figure>
<p>To translate from this to the PROV data model we use the following process:</p>
<ul>
<li><p>A start and end commit are selected using their hash or alias</p></li>
<li><p>Commits are topologically sorted</p></li>
<li><p>Commits are grouped into pairs for differencing from the most current to oldest with the oldest commit compared against the empty commit <span class="math"><em>ϵ</em></span>. This produces a sequence of commit pairs:</p></li>
</ul>
<p><br /><span class="math">(<em>c</em><sub><em>n</em></sub>, <em>c</em><sub><em>n</em> − 1</sub>)…(<em>c</em><sub>0</sub>, <em>ϵ</em>)</span><br /></p>
<ul>
<li>A diff is taken between each commit in a pair and associated with the first commit in the pair producing:</li>
</ul>
<p><br /><span class="math">(<em>c</em><sub><em>n</em></sub>, <em>d</em>(<em>c</em><sub><em>n</em></sub>, <em>c</em><sub><em>n</em> − 1</sub>))…(<em>c</em><sub>0</sub>, <em>d</em>(<em>c</em><sub>0</sub>, <em>ϵ</em>))</span><br /></p>
<ul>
<li>Each diff / commit pair is then processed into statements that can be appended to a provenance graph. The commit pairs are then processed into triples as follows:</li>
</ul>
<p>For the commit:</p>
<pre class="ttl"><code>
vcs:commit-{c.SHAHash} a prov:Activity 
  rdfs:label &#39;{c.CommitMessage}&#39; ;
  prov:startedAtTime {c.Author.Time} ;   
  prov:endedAtTime {c.Commit.Time} ;
  prov.wasAssociatedWith vcs:git-user-{c.Commit.User} ;  
  prov.wasInformedBy vcs:commit-{c.Commit.ParentCommit.SHAHash} ;
  prov.qualifiedAssociation 
    [
      a prov:Association ;
      prov:agent vcs:git-user{c.Commit.User} ;
      prov:hadRole &quot;author, comitter&quot; ;
    ]</code></pre>
<p>For each changed file in the commit:</p>
<pre class="ttl"><code>
vcs:file-{f.SHAHash}-{f.FilePath} a prov:Entity,content:ContentAsText ;
  content:chars {git repository http uri}{f.FilePath}-{f.ShaHash} ;
  prov:specializationOf {git repository http uri}{f.FilePath} ;
  prov:wasAttributedTo vcs:git-user-{f.User} ;
  prov:wasGeneratedBy vcs:commit-{c.SHAHash} ;


vcs:commit-{c.SHAHash} prov:uses cs:file-{f.SHAHash}-{f.FilePath} ;
</code></pre>
<h2 id="uri-generation">URI generation</h2>
<p>Handily, git SHA hashes are generated to identify every unique object in git - commits, individual file versions etc. Git also has the ability to generate shortened versions of the long encoded hash strings. We can also use base62 encoding to shorten them further if required.</p>
<h3 id="on-short-hash-length">On short hash length</h3>
<blockquote>
<p>Generally, eight to ten characters are more than enough to be unique within a project. One of the largest Git projects, the Linux kernel, is beginning to need 12 characters out of the possible 40 to stay unique.</p>
</blockquote>
<p>So, initial hash length selection is important. We can come up with a strategy to deal with collisions in the future and git will tell us when our hash length is no longer unique.</p>
<h3 id="dereferencability">Dereferencability</h3>
<p>Git content ids (vcs:file) should be dereferencable, either by representing the content as a property of the uri, or through the use of a service that can resolve them to the text they represent (see github raw URLs for reference). Provenance will be used as input to the resource compiler, so it needs to be able to simply access the content that the provenance graph refers to.</p>
<h3 id="resource-uri-generation">Resource URI generation</h3>
<p>The ‘prov:specialisationOf’ property is a URI that represents the resource at any version, so it is vital that we can compute the same URI with different git histories. So we cannot use a git object hash. We also cannot use an identity generation process (such as guid/uuid tricks) external to git, as this violates our idempotency requirement. So provisionally we will walk the history of the file, find the first commit and take a hash of its path and file name.</p>
<div class="references">
<p>1. Plaintext papers please. Available at: <a href="http://kieranhealy.org/blog/archives/2014/01/23/plain-text/" class="uri">http://kieranhealy.org/blog/archives/2014/01/23/plain-text/</a>.</p>
<p>2. Coombs JH, Renear AH, DeRose SJ. Markup systems and the future of scholarly text processing. <em>Commun ACM</em> 1987;30:933–947. Available at: <a href="http://doi.acm.org/10.1145/32206.32209" class="uri">http://doi.acm.org/10.1145/32206.32209</a>.</p>
<p>3. Sun C, Ellis C (Skip). Operational transformation in real-time group editors: Issues, algorithms, and achievements. 1998.</p>
<p>4. McGuinness D, Lebo T, Sahoo S. PROV-o: The PROV ontology. W3C 2013.</p>
<p>5. De Nies T, Magliacane S, Verborgh R, et al. Git2PROV: Exposing version control system content as W3C PROV. In Poster and demo proceedings of the 12th international semantic web conference. 2013. Available at: <a href="http://www.iswc2013.semanticweb.org/sites/default/files/iswc_demo_32_0.pdf" class="uri">http://www.iswc2013.semanticweb.org/sites/default/files/iswc_demo_32_0.pdf</a>.</p>
</div>
</section>
</body>
</html>